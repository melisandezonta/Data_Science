dim_old = (dim(df)[2])+1
data_frame = data.frame(map)
names(data_frame) = list.attributes.bis
data_frame_ten = select_ten_best_values(data_frame,n)
if (choice == 1){
df = cbind(df,data_frame_ten)
return(df)}
else{
return(data_frame_ten)
}
}
selection_non_numeric <- function(df){
cls <- sapply(df, class)
nonnumdf <- df %>% select(which(cls == "character"))
return(nonnumdf)
}
load('movies_merged')
df = movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end="\n", file="")
colnames(df)
library(ggplot2)
library(stringr)
library(caret)
library(tidytext)
library(dplyr)
library(ModelMetrics)
library(readr)
library(grid)
library(gridExtra)
# TODO: Remove all rows from df that do not correspond to movies`
dim(df)
df1 = subset(df,Type == "movie")
dim(df1)
df = df1
# TODO: Remove rows with missing Gross value
print(dim(df))
df = df[is.na(df$Gross) == FALSE,]
print(dim(df))
# TODO: Exclude movies released prior to 2000
print(dim(df))
df = df[df$Year >= 2000,]
print(dim(df))
# TODO: Remove mismatched rows
released.in.year = function(x){
if (is.na(x) == FALSE){
x = as.character(x)
return(as.numeric(str_sub(x,start = 1,end = 4)))
}
else {
return(x)
}
}
# Function to select only the month in the released year
released.in.month = function(x){
if (is.na(x) == FALSE){
x = as.character(x)
return(as.numeric(str_sub(x,start = 6,end = 7)))
}
else {
return(x)
}
}
# Create lists where the previous were applied
new_year = c()
new_month = c()
for (i in 1:length(df$Released)){
new_year = c(new_year,released.in.year(df$Released[i]))
new_month = c(new_month,released.in.month(df$Released[i]))
}
# Select the index of the lists (the films) which don't abide by the condition
index_remove = c()
for (i in seq(1,length(new_year))){
if (is.na(new_year[i])== FALSE){
if ((((new_year[i] == (df$Year[i]+1)) && (new_month[i] > 3))||
(new_year[i] > (df$Year[i]+1)))
|| (((new_year[i] == (df$Year[i]-1)) && (new_month[i] < 10))||
(new_year[i] < (df$Year[i]-1))))
{
index_remove = c(index_remove,i)
}
}
}
# Remove the rows
df4 = df[-index_remove,]
cat("Before removal the number of rows was", dim(df)[1], "and after it is", dim(df4)[1], ".", "The percentage of removed rows is", ((dim(df)[1]-dim(df4)[1])/dim(df)[1])*100, end="\n", file="")
df = df4
# TODO: Exclude the `Domestic_Gross` column
df$Domestic_Gross = NULL
# TODO: Replace df$Runtime with a numeric column containing the runtime in minutes
# Remove_min function allowing to delete the 'mins'
# remove_min = function(x){
# if (x != 'NA'){
#    return(str_sub(x,start = 1,end = -5))
# }
# }
remove_min <- function(x){
if (x != 'NA'){
x = as.character(x)
hours = as.numeric(str_match(x, "(\\d*) (h)")[,2])
hours[is.na(hours) == TRUE] = 0
minutes = as.numeric(str_match(x, "(\\d*) (m)")[,2])
minutes[is.na(minutes) == TRUE] = 0
if (hours > 0){
return(str_sub(60*hours + minutes))
}
else {
return(str_sub(minutes))
}
}
}
# Apply the previous function and Conversion to numeric
new = lapply(df$Runtime,remove_min)
df$Runtime = as.numeric(unlist(new))
# TODO(optional): Additional preprocessing
# Will be done after
# TODO: Print the dimensions of the final preprocessed dataset and column names
dim(df)
names(df)
# TODO: Build & evaluate model 1 (numeric variables only)
selection_numeric <- function(df){
cls <- sapply(df, class)
numdf <- df %>% select(which(cls == "numeric" | cls == 'double' | cls == 'integer'))
return(numdf)
}
df1 = selection_numeric(df)
print(dim(df1))
df1 = na.omit(df1)
print(dim(df1))
df2 = cor(df1)
hc = findCorrelation(df2, cutoff = .90, verbose = FALSE)
hc = sort(hc)
reduced_data = df1[,-c(hc)]
reduced_data$tomatoRotten = NULL
reduced_data$imdbRating = (df1$imdbRating + df1$tomatoRating + df1$tomatoUserRating)/3
df3 = reduced_data
splitdataframe <- function(dataframe,percent){
index =  1:nrow(dataframe)
training_index = sample(index, trunc((percent/100)*dim(dataframe)[1]))
trainset = dataframe[training_index,]
testset = dataframe[-training_index,]
return(list(train = trainset,test = testset))
}
prediction <- function(numdf,attribute){
a = numdf[[attribute]]
numdf[[attribute]] = NULL
numdf[[attribute]] = a
car = names(numdf)[1:length(names(numdf))-1]
car = as.list(car)
car1 = str_c(car,collapse=' + ')
car1 = paste(attribute,"~",car1)
car1 = paste(car1,"+0")
M = lm(as.formula(car1),numdf)
return(M)
}
## Ten times test
ten_times_training_rmse <- function(percent_split,df,attribute,prediction){
rmse_train = c()
rmse_test = c()
for (i in seq(1,100)){
a = c()
data = splitdataframe(df,percent_split)
train = data$train
test = data$test
a = test[["Gross"]]
test[["Gross"]] = NULL
M_train = prediction(train,"Gross")
residual_train = resid(M_train)
RMSE_train = sqrt(mean(residual_train^2))
rmse_train = c(rmse_train,RMSE_train)
test_predict = predict(M_train,test)
RMSE_test = sqrt(mean((a - test_predict)^2))
rmse_test = c(rmse_test, RMSE_test)
rmse = rbind(rmse_train,rmse_test)
}
return(rmse)
}
ten_times_training_rmse(95,df3,"Gross",prediction)
percent_split = seq(5,95,by = 5)
rmse_train = c()
rmse_test = c()
for (i in seq(1,length(percent_split))){
RMSE_train = ten_times_training_rmse(percent_split[i],df1,"Gross",prediction)
rmse_train = c(rmse_train,mean(RMSE_train[1,]))
rmse_test = c(rmse_test,mean(RMSE_train[2,]))
}
x = c(percent_split,percent_split)
data_split = as.data.frame(c(Train = rmse_train, Test = rmse_test))
data_split$Type = c(rep("Train",1,length(percent_split)),rep("Test",1,length(percent_split)))
names(data_split) = c('data','Type')
ggplot(data_split,aes(x=x,y=data,col=Type))+geom_line()+ggtitle('RMSE')+xlab('Dataset Sizes') + ylab('RMSE')
# TODO: Build & evaluate model 2 (transformed numeric variables only)
prediction2 <- function(numdf,attribute){
a = numdf[[attribute]]
numdf[[attribute]] = NULL
numdf[[attribute]] = a
car = names(numdf)[1:length(names(numdf))-1]
car = as.list(car)
car1 = str_c(car,collapse='^2 +')
car1 = paste(car1,"^2", sep = "")
car1 = paste(attribute,"~",car1)
car1 = paste(car1,"+0")
M = lm(as.formula(car1),numdf)
return(M)
}
prediction4 <- function(numdf,attribute){
a = numdf[[attribute]]
numdf[[attribute]] = NULL
numdf[[attribute]] = a
car = names(numdf)[1:length(names(numdf))-1]
car = as.list(car)
car1 = str_c(car,collapse=':')
car1 = paste(attribute,"~",car1)
car1 = paste(car1,"+0")
M = lm(as.formula(car1),numdf)
return(M)
}
prediction6 <- function(numdf,attribute){
a = numdf[[attribute]]
numdf[[attribute]] = NULL
numdf[[attribute]] = a
car = names(numdf)[1:length(names(numdf))-1]
car = as.list(car)
car1 = str_c(car,collapse='+')
car1 = paste(attribute,"~","(",car1,")","^2", sep = "")
car1 = paste(car1,"+0")
M = lm(as.formula(car1),numdf)
return(M)
}
prediction7 <- function(numdf,attribute){
a = numdf[[attribute]]
numdf[[attribute]] = NULL
numdf[[attribute]] = a
car = names(numdf)[1:length(names(numdf))-1]
car = as.list(car)
car1 = str_c(car,collapse='+')
car1 = paste(attribute,"~","I(",car1,")", sep = "")
car1 = paste(car1,"+0")
M = lm(as.formula(car1),numdf)
return(M)
}
df4 = df3
df4$binBudget=cut(df4$Budget, c(-Inf,summary(df4$Budget)[2],summary(df4$Budget)[3],summary(df4$Budget)[4],Inf), labels=1:4)
df4$Budget=NULL
df4$binRuntime=cut(df4$Runtime, c(-Inf,summary(df4$Runtime)[2],summary(df4$Runtime)[3],summary(df4$Runtime)[4],Inf), labels=1:4)
df4$Runtime=NULL
percent_split = seq(5,95,by = 5)
rmse_train_1 = c()
rmse_test_1 = c()
rmse_train_2 = c()
rmse_test_2 = c()
rmse_train_3 = c()
rmse_test_3 = c()
rmse_train_4 = c()
rmse_test_4 = c()
for (i in seq(1,length(percent_split))){
RMSE_train_1 = ten_times_training_rmse(percent_split[i],df3,"Gross",prediction2)
rmse_train_1 = c(rmse_train_1,mean(RMSE_train_1[1,]))
rmse_test_1 = c(rmse_test_1,mean(RMSE_train_1[2,]))
RMSE_train_2 = ten_times_training_rmse(percent_split[i],df3,"Gross",prediction4)
rmse_train_2 = c(rmse_train_2,mean(RMSE_train_2[1,]))
rmse_test_2 = c(rmse_test_2,mean(RMSE_train_2[2,]))
RMSE_train_3 = ten_times_training_rmse(percent_split[i],df3,"Gross",prediction6)
rmse_train_3 = c(rmse_train_3,mean(RMSE_train_3[1,]))
rmse_test_3 = c(rmse_test_3,mean(RMSE_train_3[2,]))
RMSE_train_4 = ten_times_training_rmse(percent_split[i],df3,"Gross",prediction7)
rmse_train_4 = c(rmse_train_4,mean(RMSE_train_4[1,]))
rmse_test_4 = c(rmse_test_4,mean(RMSE_train_4[2,]))
}
x = c(percent_split,percent_split,percent_split,percent_split)
data_split_1 = as.data.frame(c(rmse_train_1,  rmse_test_1))
names(data_split_1)="data"
data_split_2 = as.data.frame(c( rmse_train_2,  rmse_test_2))
names(data_split_2)="data"
data_split_3 = as.data.frame(c( rmse_train_3,  rmse_test_3))
names(data_split_3)="data"
data_split_4 = as.data.frame(c( rmse_train_4,  rmse_test_4))
names(data_split_4)="data"
data_split = rbind(data_split_1,data_split_2,data_split_3,data_split_4)
data_split$Type = c(rep("Prediction 1",2*length(percent_split)),rep("Prediction 2",2*length(percent_split)),rep("Prediction 3",2*length(percent_split)),rep("Prediction 4",2*length(percent_split)))
data_split$Category =  c(rep("Train",length(percent_split)),rep("Test",length(percent_split)),rep("Train",length(percent_split)),rep("Test",length(percent_split)),rep("Train",length(percent_split)),rep("Test",length(percent_split)),rep("Train",length(percent_split)),rep("Test",length(percent_split)))
data_split$x=x
#names(data_split) = c('data','Type')
ggplot(data_split,aes(x=x,y=data,color=Type, linetype = Category))+geom_line()+ggtitle('RMSE')+xlab('Dataset Sizes') + ylab('RMSE')+
ylim(c(0.5e8,1.7e8))
# TODO: Build & evaluate model 3 (converted non-numeric variables only)
select_ten_best_values <- function(df,n){
list = c()
# Sum all the 1 in each column
list = lapply(df,sum)
data_frame.to.be.ordered = data.frame(list)
names(data_frame.to.be.ordered) = names(df)
# Order the list in decreasing sum
data_frame.ordered = data_frame.to.be.ordered[rev(order(sapply(list,'[[',1)))]
# Create the data frame for the most common types
data.frame.10.first.values = unlist(data_frame.ordered[,1:n], use.names=TRUE)
data.frame.10.first = df[,names(data.frame.10.first.values)]
return(data.frame.10.first)
}
binary_conversion <- function(df,attribute,n,choice = 1){
df[[attribute]] = gsub(" ", "", df[[attribute]])
list_attributes = c()
temp_attributes = c()
for (i in seq(1,length(df[[attribute]]))) {
temp_attributes = unlist(strsplit(df[[attribute]][i],","))
list_attributes = c(list_attributes,temp_attributes)
}
duplicated.values = which(duplicated(list_attributes))
list.attributes.bis = list_attributes[-duplicated.values]
list.attributes.bis = sort(list.attributes.bis)
map = matrix(0,length(df[[attribute]]),length(list.attributes.bis))
for (j in seq(1,length(df[[attribute]]))){
temp_attributes = unlist(strsplit(df[[attribute]][j],","))
for (k in seq(1,length(temp_attributes))){
index = which(temp_attributes[k] == list.attributes.bis)
map[j,index] = 1
}
}
dim_old = (dim(df)[2])+1
data_frame = data.frame(map)
names(data_frame) = list.attributes.bis
data_frame_ten = select_ten_best_values(data_frame,n)
if (choice == 1){
df = cbind(df,data_frame_ten)
return(df)}
else{
return(data_frame_ten)
}
}
selection_non_numeric <- function(df){
cls <- sapply(df, class)
nonnumdf <- df %>% select(which(cls == "character"))
return(nonnumdf)
}
load("movies_merged")
load("movies_merged")
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
library(foreach)
library(doParallel)
library(ggplot2)
library(caret)
library(tm)
library(qdapTools)
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
library(foreach)
library(doParallel)
library(ggplot2)
library(caret)
library(tm)
library(qdapTools)
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
library(foreach)
library(doParallel)
library(ggplot2)
library(caret)
library(tm)
library(qdapTools)
# TODO: Remove all rows from df that do not correspond to movies
cat("Dataset has", nrow(df)[1], "before removing non-movies instances.\n")
df <- subset(df, Type == "movie")
cat("Dataset has", nrow(df)[1], "after removing non-movies instances.")
# function to evaluate a model (or formula) over a dataset for different training and testing
# dataset sizes and multiple (100) times to have consistent and repeatable results
evaluate.model <- function(formula, df) {
cl <- makeCluster(detectCores())
registerDoParallel(cl)
RMSE <- foreach(i = seq(0.05, 0.95, 0.05), .combine = rbind) %dopar% {
RMSE.part <- data.frame()
for (j in 1:100) {
n <- nrow(df)
s <- sample(seq(1, n), round(i * n), replace = FALSE)
df.train <- df[s, ]
df.test <- df[-s, ]
M <- lm(formula, df.train)
RMSE.train <- sqrt(mean((predict(M, df.train) - df.train$Gross)^2))
RMSE.test <- sqrt(mean((predict(M, df.test) - df.test$Gross)^2))
RMSE.part <- rbind(RMSE.part, cbind(RMSE.train, RMSE.test, perc = i))
}
RMSE.part
}
stopCluster(cl)
tmp <- data.frame(RMSE = RMSE$RMSE.train, perc = RMSE$perc, phase = rep("train", nrow(RMSE)))
tmp2 <- data.frame(RMSE = RMSE$RMSE.test, perc = RMSE$perc, phase = rep("test", nrow(RMSE)))
RMSE <- rbind(tmp, tmp2)
RMSE.mean <- aggregate(RMSE, list(perc = RMSE$perc, phase = RMSE$phase), FUN = mean)[, 1:3]
return(RMSE.mean)
}
# TODO: Build & evaluate model 1 (numeric variables only)
df.model <- df
df.model$Gross <- NULL
cor <- cor(df.model[, sapply(df.model, is.numeric)])
col.2.remove <- findCorrelation(cor, cutoff = 0.9, names = TRUE, exact = TRUE)
df.model <- df.model[, !names(df.model) %in% col.2.remove]
formula <- as.formula(paste("Gross~", paste(names(df.model[, sapply(df.model, is.numeric)]), sep = "", collapse = "+"), sep = "", collapse = "~"))
formula
RMSE.1 <- evaluate.model(formula, df)
load("movies_merged")
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
library(foreach)
library(doParallel)
library(ggplot2)
library(caret)
library(tm)
library(qdapTools)
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
library(foreach)
library(doParallel)
library(ggplot2)
library(caret)
library(tm)
library(qdapTools)
# TODO: Remove all rows from df that do not correspond to movies
cat("Dataset has", nrow(df)[1], "before removing non-movies instances.\n")
df <- subset(df, Type == "movie")
cat("Dataset has", nrow(df)[1], "after removing non-movies instances.")
load("movies_merged")
df <- movies_merged
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
library(foreach)
library(doParallel)
library(ggplot2)
library(caret)
library(tm)
library(qdapTools)
# TODO: Remove all rows from df that do not correspond to movies
cat("Dataset has", nrow(df)[1], "before removing non-movies instances.\n")
df <- subset(df, Type == "movie")
cat("Dataset has", nrow(df)[1], "after removing non-movies instances.")
# TODO: Remove rows with missing Gross value
cat("Dataset has", nrow(df)[1], "before removing instances with missing Gross value.\n")
df <- subset(df, !is.na(df$Gross))
cat("Dataset has", nrow(df)[1], "after removing instances with missing Gross value.")
# TODO: Remove mismatched rows
previousNrow <- nrow(df)
# remove the films whose Year and Released differ for more than three months
ReleasedYear <- as.numeric(sapply(df$Released, function(x) strsplit(as.String(x), "-")[[1]][1]))
ReleasedMonth <- as.numeric(sapply(df$Released, function(x) strsplit(as.String(x), "-")[[1]][2]))
df <- df[which((df$Year == ReleasedYear - 1 & ReleasedMonth - 3 < 1)
| df$Year == ReleasedYear
| (df$Year == ReleasedYear + 1 & ReleasedMonth + 3 > 12)
| is.na(df$Year)
| is.na(ReleasedYear)), ]
cat("I removed", previousNrow - nrow(df), "rows, which correspond to ", (abs(nrow(df) - previousNrow)/previousNrow) * 100, "% of the rows.")
# TODO: Exclude the `Domestic_Gross` column
df$Domestic_Gross <- NULL
# TODO: Replace df$Runtime with a numeric column containing the runtime in minutes
# process Runtime by keeping the first word and parsing it as numeric, missing values will be kept as NA
df$Runtime <- as.numeric(sapply(strsplit(df$Runtime, " "), `[`, 1))
# TODO(optional): Additional preprocessing
# remove rows with missing values
df = na.omit(df)
# TODO: Print the dimensions of the final preprocessed dataset and column names
cat("Dataset has", dim(df)[1], "rows and", dim(df)[2], "columns", end = "\n", file = "")
colnames(df)
# function to evaluate a model (or formula) over a dataset for different training and testing
# dataset sizes and multiple (100) times to have consistent and repeatable results
evaluate.model <- function(formula, df) {
cl <- makeCluster(detectCores())
registerDoParallel(cl)
RMSE <- foreach(i = seq(0.05, 0.95, 0.05), .combine = rbind) %dopar% {
RMSE.part <- data.frame()
for (j in 1:100) {
n <- nrow(df)
s <- sample(seq(1, n), round(i * n), replace = FALSE)
df.train <- df[s, ]
df.test <- df[-s, ]
M <- lm(formula, df.train)
RMSE.train <- sqrt(mean((predict(M, df.train) - df.train$Gross)^2))
RMSE.test <- sqrt(mean((predict(M, df.test) - df.test$Gross)^2))
RMSE.part <- rbind(RMSE.part, cbind(RMSE.train, RMSE.test, perc = i))
}
RMSE.part
}
stopCluster(cl)
tmp <- data.frame(RMSE = RMSE$RMSE.train, perc = RMSE$perc, phase = rep("train", nrow(RMSE)))
tmp2 <- data.frame(RMSE = RMSE$RMSE.test, perc = RMSE$perc, phase = rep("test", nrow(RMSE)))
RMSE <- rbind(tmp, tmp2)
RMSE.mean <- aggregate(RMSE, list(perc = RMSE$perc, phase = RMSE$phase), FUN = mean)[, 1:3]
return(RMSE.mean)
}
# TODO: Build & evaluate model 1 (numeric variables only)
df.model <- df
df.model$Gross <- NULL
cor <- cor(df.model[, sapply(df.model, is.numeric)])
col.2.remove <- findCorrelation(cor, cutoff = 0.9, names = TRUE, exact = TRUE)
df.model <- df.model[, !names(df.model) %in% col.2.remove]
formula <- as.formula(paste("Gross~", paste(names(df.model[, sapply(df.model, is.numeric)]), sep = "", collapse = "+"), sep = "", collapse = "~"))
formula
RMSE.1 <- evaluate.model(formula, df)
